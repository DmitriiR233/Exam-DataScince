# Indian Climate ML Project

Сессионный проект по машинному обучению: реализация линейной и логистической регрессии **с нуля на numpy**, а также сравнение с моделью Random Forest на данных о климате городов Индии за 2024–2025 годы.

## 1. Описание проекта

В проекте решаются три основные задачи:

1. **Линейная регрессия**  
   - Реализация градиентного спуска (mini-batch) для предсказания средней температуры `TemperatureAvg C` по набору метеопараметров.  
   - Рассчитываются MSE, RMSE, MAE на train/test и строятся графики сходимости и «факт vs предсказание».

2. **Логистическая регрессия (binary-классификация)**  
   - Реализация логистической регрессии с нуля: сигмоида, логистический лосс, градиентный спуск (mini-batch), опциональная L2‑регуляризация.  
   - Задача: бинарная классификация «жаркий день» / «не жаркий день» (по порогу на `TemperatureAvg C`).

3. **Классификация двумя подходами**  
   - Собственная логистическая регрессия (реализация с нуля).  
   - Модель **Random Forest** из библиотеки `scikit-learn` как второй подход.  
   - Сравнение моделей по метрикам: accuracy, precision, recall, F1, confusion matrix, ROC AUC.

Помимо этого, проводятся эксперименты с гиперпараметрами (learning rate, количество эпох, размер батча) и анализируется влияние на сходимость и качество моделей.

## 2. Данные

- Файл: `data/Indian_Climate_Dataset_2024_2025.csv`.  
- Тип данных: табличные (CSV), более 7000 строк, признаки включают:
  - `Date`, `City`, `State`  
  - `TemperatureMax C`, `TemperatureMin C`, `TemperatureAvg C`  
  - `Humidity`, `Rainfall mm`, `WindSpeed kmh`  
  - `AQI`, `AQICategory`, `Pressure hPa`, `CloudCover`.  

Использование в задачах:

- **Регрессия:** целевая переменная `TemperatureAvg C`.  
- **Классификация:** бинарная цель — жаркий день (1), если `TemperatureAvg C` > медианы, иначе 0.

## 3. Структура репозитория

- `notebooks/`  
  - `project.ipynb` — основной Jupyter Notebook с кодом и графиками.
- `data/`  
  - `Indian_Climate_Dataset_2024_2025.csv` — исходный датасет.
- `requirements.txt` — список зависимостей для установки окружения.
- `README.md` — текущий файл с описанием проекта.
- `report.pdf` — краткий отчёт (до 6 страниц) с формулами и результатами.

## 4. Запуск локально

### 4.1. Клонирование репозитория
git clone https://github.com/<your_username>/<your_repo>.git
cd <your_repo>


### 4.2. Создание виртуального окружения и установка зависимостей

python -m venv venv
source venv/bin/activate # Windows: venv\Scripts\activate
pip install -r requirements.txt

`requirements.txt` должен содержать, как минимум:
- numpy==2.0.2
- pandas==2.2.2
- matplotlib==3.10.0
- seaborn==0.13.2
- scikit-learn==1.6.1
- jupyter


### 4.3. Запуск Jupyter Notebook


Далее открыть файл `notebooks/project.ipynb` и последовательно выполнить все ячейки сверху вниз.

## 5. Запуск в Google Colab

1. Открыть ссылку на Colab-ноутбук, указанную в отчёте/репозитории.  
2. Убедиться, что предоставлены права просмотра для преподавателя (через настройки доступа).  
3. При необходимости загрузить файл `Indian_Climate_Dataset_2024_2025.csv` в Colab или подключить Google Drive.  
4. Выполнить ячейки по порядку; все зависимости уже доступны в среде Colab.

## 6. Реализация моделей

### 6.1. Линейная регрессия (с нуля)

- Подготовка признаков (нормализация Z‑score, добавление bias).  
- Mini‑batch SGD:  
  - функция потерь MSE;  
  - аналитический градиент;  
  - обновление весов.  
- Разделение на train/test; расчёт MSE, RMSE, MAE; графики сходимости и «факт vs предсказание».

### 6.2. Логистическая регрессия (с нуля)

- Реализация сигмоиды и логистического лосса.  
- Mini‑batch SGD, возможность L2‑регуляризации.  
- Разделение на train/test.  
- Метрики: accuracy, precision, recall, F1-score, confusion matrix, ROC AUC для бинарной классификации.

### 6.3. Random Forest (сквозь sklearn)

- Использует те же признаки и разбиение train/test, что и логистическая регрессия.  
- Обучение `RandomForestClassifier`, получение предсказаний и вероятностей.  
- Расчёт тех же метрик и сравнение с логистической регрессией.

## 7. Эксперименты

В ноутбуке проведены эксперименты:

- Влияние `learning_rate`, `epochs`, `batch_size` на сходимость градиентного спуска для логистической (и/или линейной) регрессии — графики зависимости лосса от итераций.
- Сравнение качества логистической регрессии и Random Forest на тестовой выборке с анализом возможного переобучения.

## 8. Авторы

- Романюк Дмитрий, Омирзаков Азаматик 
- DS-23B, 3 курс 




